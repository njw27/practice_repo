{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcf0a6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320d27aa",
   "metadata": {},
   "source": [
    "NLP - WRITER ANALYZER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f840711",
   "metadata": {},
   "source": [
    "To answer the question once and for all if Kit Marlowe was Shakespeare and vice versa. Will import boths' complete works. Will create the \"Marlowe detector\" based on about 70% of Marlowe's work. Will test with unseen confirmed Marlowe plays to confirm it is working. Then will test on some Shakespeare work to see what the score is.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680d4009",
   "metadata": {},
   "source": [
    "Source texts as .txt files from Project Gutenberg. Individual Plays. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32144b68",
   "metadata": {},
   "source": [
    "Download individual books? Or Collection?\n",
    "Individual folders?\n",
    "Or one big?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f78f0d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "Test Text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc0b5a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "        def stemmer(text):\n",
    "            # Write your code here\n",
    "            text2 = str(text)\n",
    "            text = text2.split()\n",
    "            new_text = []\n",
    "            new_text2=[]\n",
    "            for word in text:\n",
    "                if word.endswith('ed'):\n",
    "                    new_word = word[:-2]\n",
    "                    new_text.append(new_word)\n",
    "                elif word.endswith('ly'):\n",
    "                    new_word = word[:-2]\n",
    "                    new_text.append(new_word)\n",
    "                elif word.endswith('ing'):\n",
    "                    new_word = word[:-3]\n",
    "                    new_text.append(new_word)\n",
    "                else:\n",
    "                    new_text.append(word)\n",
    "            for word in new_text:\n",
    "                if len(word)>8:\n",
    "                    new_word2 = word[:8]\n",
    "                    new_text2.append(new_word2)\n",
    "                else:\n",
    "                    new_text2.append(word)\n",
    "            return \" \".join(new_text2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b40107a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello my excellen read leaver wry'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer(\"hello my excellent reading leavered wryly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51f36e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import ascii_lowercase\n",
    "\n",
    "def cr(mes, rotation=4):\n",
    "    rotated = ascii_lowercase[rotation:]+ascii_lowercase[:rotation]\n",
    "    cipher = {o in n for o, n in zip(ascii_lowercase,rotated)}\n",
    "    \n",
    "    encoded = []\n",
    "    for char in mes.lower():\n",
    "        if char in cipher:\n",
    "            encoded.append(cipher[char])\n",
    "        else:\n",
    "            encoded.append(char)\n",
    "    return \" \".join(encoded)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adfc98b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'h e l l o   m y   d e a r   m a n  '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr(\"HELLO MY dEAR man \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67c75ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from https://programminghistorian.org/en/lessons/introduction-to-stylometry-with-python\n",
    "#a major resource\n",
    "\n",
    "\n",
    "\n",
    "papers = {\n",
    "    'Madison': [10, 14, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48],\n",
    "    'Hamilton': [1, 6, 7, 8, 9, 11, 12, 13, 15, 16, 17, 21, 22, 23, 24,\n",
    "                 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 59, 60,\n",
    "                 61, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77,\n",
    "                 78, 79, 80, 81, 82, 83, 84, 85],\n",
    "    'Jay': [2, 3, 4, 5],\n",
    "    'Shared': [18, 19, 20],\n",
    "    'Disputed': [49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 62, 63],\n",
    "    'TestCase': [64]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84628982",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from https://programminghistorian.org/en/lessons/introduction-to-stylometry-with-python\n",
    "#a major resource\n",
    "\n",
    "\n",
    "# A function that compiles all of the text files associated with a single author into a single string\n",
    "def read_files_into_string(filenames):\n",
    "    strings = []\n",
    "    for filename in filenames:\n",
    "        with open(f'data/federalist_{filename}.txt') as f:\n",
    "            strings.append(f.read())\n",
    "    return '\\n'.join(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64835694",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/federalist_10.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-617a5741b390>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfederalist_by_author\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mauthor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpapers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mfederalist_by_author\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mauthor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_files_into_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-9a8f46405952>\u001b[0m in \u001b[0;36mread_files_into_string\u001b[0;34m(filenames)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mstrings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'data/federalist_{filename}.txt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mstrings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/federalist_10.txt'"
     ]
    }
   ],
   "source": [
    "# Make a dictionary out of the authors' corpora\n",
    "federalist_by_author = {}\n",
    "for author, files in papers.items():\n",
    "    federalist_by_author[author] = read_files_into_string(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00875f03",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Madison'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-6bae687f3c3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mauthor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpapers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfederalist_by_author\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mauthor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'Madison'"
     ]
    }
   ],
   "source": [
    "for author in papers:\n",
    "    print(federalist_by_author[author][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e6e83b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd03235b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdde775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c811c66d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Hamilton'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d8eba3722731>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mfederalist_by_author_length_distributions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mauthor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mauthors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfederalist_by_author\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mauthor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Filter out punctuation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Hamilton'"
     ]
    }
   ],
   "source": [
    "# Load nltk\n",
    "import nltk\n",
    "%matplotlib inline\n",
    "\n",
    "# Compare the disputed papers to those written by everyone,\n",
    "# including the shared ones.\n",
    "authors = (\"Hamilton\", \"Madison\", \"Disputed\", \"Jay\", \"Shared\")\n",
    "\n",
    "# Transform the authors' corpora into lists of word tokens\n",
    "federalist_by_author_tokens = {}\n",
    "federalist_by_author_length_distributions = {}\n",
    "for author in authors:\n",
    "    tokens = nltk.word_tokenize(federalist_by_author[author])\n",
    "\n",
    "    # Filter out punctuation\n",
    "    federalist_by_author_tokens[author] = ([token for token in tokens\n",
    "                                            if any(c.isalpha() for c in token)])\n",
    "\n",
    "    # Get a distribution of token lengths\n",
    "    token_lengths = [len(token) for token in federalist_by_author_tokens[author]]\n",
    "    federalist_by_author_length_distributions[author] = nltk.FreqDist(token_lengths)\n",
    "    federalist_by_author_length_distributions[author].plot(15,title=author)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f25afacb",
   "metadata": {},
   "source": [
    "Source Listed Above!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9c6496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68599d72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf768b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761c2d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
