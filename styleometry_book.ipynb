{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b7cf445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bd0cf0",
   "metadata": {},
   "source": [
    "NLP - WRITER ANALYZER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2b5a05",
   "metadata": {},
   "source": [
    "To answer the question once and for all if Kit Marlowe was Shakespeare and vice versa. Will import boths' complete works. Will create the \"Marlowe detector\" based on about 70% of Marlowe's work. Will test with unseen confirmed Marlowe plays to confirm it is working. Then will test on some Shakespeare work to see what the score is.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90d51e3",
   "metadata": {},
   "source": [
    "Source texts as .txt files from Project Gutenberg/z-Library (all are public domain)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df90c623",
   "metadata": {},
   "source": [
    "## Phase 1 - Proof of Concept \n",
    "\n",
    "Will compare style of all plays of Marlowe I could get my hands on (Faustus was listed like 5 times for some reason). Will compare to another of Marlowe's plays that was not part of the style basis and will compare to one play of Shakespeare, King Lear. \n",
    "\n",
    "\n",
    "## Phase 2 - Cleaner Version with More Writing as Basis \n",
    "\n",
    "When the process has been figured out, I have the much easier to find complete collection of Shakespeare's work. That will serve as the style basis to check again if Shakespeare was Marlowe. This will be gone on a few of Marlowe's singular plays and should hopefully get similar scores to Phase 1.\n",
    "\n",
    "\n",
    "## Phase 3 - The Workspace\n",
    "\n",
    "Will have a basic UI where you can upload input in a file type (.txt) either through upload or a folder location. Then your text you want to scan will be input as well. The software will create the new style blueprint and then compare the file you want to compare.\n",
    "\n",
    "\n",
    "## Phase 4 - Advanced Product\n",
    "\n",
    "Will make a database of prolific writer's styles (Kit Marlowe, William Shakespeare, Mark Twain, Agatha Christie, Stephen King, etc). All you have to do is input the text you want to examine, and the software will run and show you how similar it is to each writer's style in descending order. \n",
    "\n",
    "Will have authors to check against by default and allow you to set which you want to compare to if you don't want to do all. (Also may affect runtime if its less than a couple seconds)\n",
    "\n",
    "Will still have an option to create a new writer style profile and add it to saved authors list. \n",
    "\n",
    "Maybe make the UI visually cool\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e86eb3f",
   "metadata": {},
   "source": [
    "# Challenges to consider\n",
    "\n",
    "Cleaning all the texts to remove legal text/publisher data\n",
    "\n",
    "Cleaning any odd symbols (will be done with the stemmer etc)\n",
    "\n",
    "Character names will come up. Consider swapping with just the name CHARACTER or ACTOR for all of them\n",
    "\n",
    "Will the sonnets/poetry need to be eliminated/stemmed?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09f9fb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "        def stemmer(text):\n",
    "            # Write your code here\n",
    "            text2 = str(text)\n",
    "            text = text2.split()\n",
    "            new_text = []\n",
    "            new_text2=[]\n",
    "            for word in text:\n",
    "                if word.endswith('ed'):\n",
    "                    new_word = word[:-2]\n",
    "                    new_text.append(new_word)\n",
    "                elif word.endswith('ly'):\n",
    "                    new_word = word[:-2]\n",
    "                    new_text.append(new_word)\n",
    "                elif word.endswith('ing'):\n",
    "                    new_word = word[:-3]\n",
    "                    new_text.append(new_word)\n",
    "                else:\n",
    "                    new_text.append(word)\n",
    "            for word in new_text:\n",
    "                if len(word)>8:\n",
    "                    new_word2 = word[:8]\n",
    "                    new_text2.append(new_word2)\n",
    "                else:\n",
    "                    new_text2.append(word)\n",
    "            return \" \".join(new_text2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c9b6e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello my excellen read leaver wry'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer(\"hello my excellent reading leavered wryly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a495b4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import ascii_lowercase\n",
    "\n",
    "def cr(mes, rotation=4):\n",
    "    rotated = ascii_lowercase[rotation:]+ascii_lowercase[:rotation]\n",
    "    cipher = {o in n for o, n in zip(ascii_lowercase,rotated)}\n",
    "    \n",
    "    encoded = []\n",
    "    for char in mes.lower():\n",
    "        if char in cipher:\n",
    "            encoded.append(cipher[char])\n",
    "        else:\n",
    "            encoded.append(char)\n",
    "    return \" \".join(encoded)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "098900db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'h e l l o   m y   d e a r   m a n  '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr(\"HELLO MY dEAR man \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "829f81ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from https://programminghistorian.org/en/lessons/introduction-to-stylometry-with-python\n",
    "#a major resource\n",
    "\n",
    "\n",
    "\n",
    "papers = {\n",
    "    'Madison': [10, 14, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48],\n",
    "    'Hamilton': [1, 6, 7, 8, 9, 11, 12, 13, 15, 16, 17, 21, 22, 23, 24,\n",
    "                 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 59, 60,\n",
    "                 61, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77,\n",
    "                 78, 79, 80, 81, 82, 83, 84, 85],\n",
    "    'Jay': [2, 3, 4, 5],\n",
    "    'Shared': [18, 19, 20],\n",
    "    'Disputed': [49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 62, 63],\n",
    "    'TestCase': [64]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d293c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from https://programminghistorian.org/en/lessons/introduction-to-stylometry-with-python\n",
    "#a major resource\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# A function that compiles all of the text files associated with a single author into a single string\n",
    "def read_files_into_string(filenames):\n",
    "    strings = []\n",
    "    for filename in filenames:\n",
    "        with open(f'data/federalist_{filename}.txt') as f:\n",
    "            strings.append(f.read())\n",
    "    return '\\n'.join(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d215351a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/federalist_10.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-617a5741b390>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfederalist_by_author\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mauthor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpapers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mfederalist_by_author\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mauthor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_files_into_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-9a8f46405952>\u001b[0m in \u001b[0;36mread_files_into_string\u001b[0;34m(filenames)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mstrings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'data/federalist_{filename}.txt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mstrings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/federalist_10.txt'"
     ]
    }
   ],
   "source": [
    "# Make a dictionary out of the authors' corpora\n",
    "federalist_by_author = {}\n",
    "for author, files in papers.items():\n",
    "    federalist_by_author[author] = read_files_into_string(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "196b3523",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Madison'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-6bae687f3c3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mauthor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpapers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfederalist_by_author\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mauthor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'Madison'"
     ]
    }
   ],
   "source": [
    "for author in papers:\n",
    "    print(federalist_by_author[author][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8817fbc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b26f46d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af7d16a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61c17013",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Hamilton'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d8eba3722731>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mfederalist_by_author_length_distributions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mauthor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mauthors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfederalist_by_author\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mauthor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Filter out punctuation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Hamilton'"
     ]
    }
   ],
   "source": [
    "# Load nltk\n",
    "import nltk\n",
    "%matplotlib inline\n",
    "\n",
    "# Compare the disputed papers to those written by everyone,\n",
    "# including the shared ones.\n",
    "authors = (\"Hamilton\", \"Madison\", \"Disputed\", \"Jay\", \"Shared\")\n",
    "\n",
    "# Transform the authors' corpora into lists of word tokens\n",
    "federalist_by_author_tokens = {}\n",
    "federalist_by_author_length_distributions = {}\n",
    "for author in authors:\n",
    "    tokens = nltk.word_tokenize(federalist_by_author[author])\n",
    "\n",
    "    # Filter out punctuation\n",
    "    federalist_by_author_tokens[author] = ([token for token in tokens\n",
    "                                            if any(c.isalpha() for c in token)])\n",
    "\n",
    "    # Get a distribution of token lengths\n",
    "    token_lengths = [len(token) for token in federalist_by_author_tokens[author]]\n",
    "    federalist_by_author_length_distributions[author] = nltk.FreqDist(token_lengths)\n",
    "    federalist_by_author_length_distributions[author].plot(15,title=author)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9f39d42d",
   "metadata": {},
   "source": [
    "Source Listed Above!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c55789",
   "metadata": {},
   "source": [
    "# Background on the theory itself\n",
    "\n",
    "Via [Wikipedia](https://en.wikipedia.org/wiki/Marlovian_theory_of_Shakespeare_authorship) for now:\n",
    "\n",
    "The Marlovian theory of Shakespeare authorship holds that the Elizabethan poet and playwright Christopher Marlowe was the main author of the poems and plays attributed to William Shakespeare. Further, the theory says Marlowe did not die in Deptford on 30 May 1593, as the historical records state, but that his death was faked.\n",
    "\n",
    "Marlovians (as those who subscribe to the theory are usually called) base their argument on supposed anomalies surrounding Marlowe's reported death[1] and on the significant influence which, according to most scholars, Marlowe's works had on those of Shakespeare.[2] They also point out the coincidence that, despite their having been born only two months apart, the first time the name William Shakespeare is known to have been connected with any literary work was with the publication of Venus and Adonis just a week or two after the death of Marlowe.\n",
    "\n",
    "The argument against this is that Marlowe's death was accepted as genuine by sixteen jurors at an inquest held by the Queen's personal coroner,[3] that everyone apparently thought that he was dead at the time, and that there is a complete lack of direct evidence supporting his survival beyond 1593.[4] While there are similarities between their works,[5] Marlowe's style,[6] vocabulary,[7] imagery,[8] and his apparent weaknesses—particularly in the writing of comedy[9]—are said to be too different from Shakespeare's to be compatible with the claims of the Marlovians. The convergence of documentary evidence of the type used by academics for authorial attribution—title pages, testimony by other contemporary poets and historians, and official records—sufficiently establishes Shakespeare of Stratford's authorship for the overwhelming majority of Shakespeare scholars and literary historians,[10] who consider the Marlovian theory, like all other alternative theories of Shakespeare authorship, a fringe theory.[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703b29cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199fb2e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016ac4a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51ccfc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b133b109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91d3304c",
   "metadata": {},
   "source": [
    "# ALT Uses\n",
    "\n",
    "- IDing author of book\n",
    "- ID author of online author from \"digital fingerprint\" - possibly evil uses tbh\n",
    "- Authentication of user on one end. If you write in the same style over several instances/found in system you are likely user X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855dfa88",
   "metadata": {},
   "source": [
    "# ALT PREBUILT\n",
    "https://freelancedatascientist.net/fast-stylometry-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59332335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faststylometry\n",
      "  Downloading faststylometry-0.5.tar.gz (7.1 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from faststylometry) (1.18.5)\n",
      "Requirement already satisfied: pandas>=1.1.2 in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from faststylometry) (1.4.2)\n",
      "Requirement already satisfied: scikit-learn>=0.23.1 in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from faststylometry) (1.0.2)\n",
      "Requirement already satisfied: nltk>=3.5 in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from faststylometry) (3.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from pandas>=1.1.2->faststylometry) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from pandas>=1.1.2->faststylometry) (2.8.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from scikit-learn>=0.23.1->faststylometry) (0.17.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from scikit-learn>=0.23.1->faststylometry) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from scikit-learn>=0.23.1->faststylometry) (2.1.0)\n",
      "Requirement already satisfied: click in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from nltk>=3.5->faststylometry) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from nltk>=3.5->faststylometry) (4.50.2)\n",
      "Requirement already satisfied: regex in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from nltk>=3.5->faststylometry) (2020.10.11)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas>=1.1.2->faststylometry) (1.15.0)\n",
      "Building wheels for collected packages: faststylometry\n",
      "  Building wheel for faststylometry (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for faststylometry: filename=faststylometry-0.5-py3-none-any.whl size=8478 sha256=13c0965e88b742f263fd037a875c2ff10677ce56e5ad3d2e9b400d65fe8b051e\n",
      "  Stored in directory: /Users/nicholaswertz/Library/Caches/pip/wheels/ca/53/85/ef936668cea2afa13c65db00d8cfa05079600d1261bc054a8a\n",
      "Successfully built faststylometry\n",
      "Installing collected packages: faststylometry\n",
      "Successfully installed faststylometry-0.5\n"
     ]
    }
   ],
   "source": [
    "!pip install faststylometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e3d9f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e07578",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
